{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization Benchmark\n",
    "\n",
    "This notebook benchmarks the `ResultsSummarizer` using multiple models via Azure OpenAI\n",
    "to generate summaries for the sample queryset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "from typing import Callable, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "from nlweb_core.summarizer import ResultsSummarizer\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_result_fields(result: dict) -> dict:\n",
    "    \"\"\"Extract name and description from schema.org result data.\"\"\"\n",
    "    content = result.get(\"content\", \"{}\")\n",
    "    if isinstance(content, str):\n",
    "        try:\n",
    "            content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            content = {}\n",
    "\n",
    "    # Try various schema.org fields for name\n",
    "    name = (\n",
    "        content.get(\"headline\")\n",
    "        or content.get(\"name\")\n",
    "        or content.get(\"caption\")\n",
    "        or result.get(\"url\", \"Unknown\")\n",
    "    )\n",
    "\n",
    "    # Try various fields for description\n",
    "    description = (\n",
    "        content.get(\"description\")\n",
    "        or content.get(\"articleSection\", \"\")\n",
    "        or \"\"\n",
    "    )\n",
    "    if isinstance(description, list):\n",
    "        description = \", \".join(description)\n",
    "\n",
    "    return {\"name\": name, \"description\": description}\n",
    "\n",
    "\n",
    "async def run_summarization(\n",
    "    df: pd.DataFrame,\n",
    "    llm: Callable[[str, Dict[str, Any]], Any],\n",
    "    model_name: str,\n",
    "    concurrency: int = 4,\n",
    ") -> list:\n",
    "    \"\"\"Run summarization on all queries with the given LLM.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with query_text and ranked_results columns\n",
    "        llm: Async callable with signature (prompt, schema) -> dict\n",
    "        model_name: Name of model for progress output\n",
    "        concurrency: Max concurrent requests\n",
    "\n",
    "    Returns:\n",
    "        List of summaries (or None for failures)\n",
    "    \"\"\"\n",
    "    summarizer = ResultsSummarizer(llm=llm)\n",
    "    semaphore = asyncio.Semaphore(concurrency)\n",
    "\n",
    "    async def process_row(idx: int, row):\n",
    "        async with semaphore:\n",
    "            raw_results = row[\"ranked_results\"][:3]\n",
    "            results = [extract_result_fields(r) for r in raw_results]\n",
    "\n",
    "            result = await summarizer.summarize(row[\"query_text\"], results)\n",
    "            print(f\"[{model_name}] Processed {idx + 1}/{len(df)}\")\n",
    "            return result.summary if result else None\n",
    "\n",
    "    tasks = [process_row(idx, row) for idx, row in df.iterrows()]\n",
    "    return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 queries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>ranked_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find reviews and recommendations f...</td>\n",
       "      <td>[{'url': 'https://www.ambitiouskitchen.com/bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is big data really skillcrush</td>\n",
       "      <td>[{'url': 'https://skillcrush.com/blog/what-is-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>growth secrets from tinder uber twitch andrew ...</td>\n",
       "      <td>[{'url': 'https://tim.blog/2021/11/30/andrew-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stories about hiking in california trinity alp...</td>\n",
       "      <td>[{'url': 'https://www.backpacker.com/stories/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who photographed Paulina Porizkova for the joy...</td>\n",
       "      <td>[{'url': 'https://www.thefashionspot.com/forum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0  Where can I find reviews and recommendations f...   \n",
       "1                 what is big data really skillcrush   \n",
       "2  growth secrets from tinder uber twitch andrew ...   \n",
       "3  stories about hiking in california trinity alp...   \n",
       "4  Who photographed Paulina Porizkova for the joy...   \n",
       "\n",
       "                                      ranked_results  \n",
       "0  [{'url': 'https://www.ambitiouskitchen.com/bea...  \n",
       "1  [{'url': 'https://skillcrush.com/blog/what-is-...  \n",
       "2  [{'url': 'https://tim.blog/2021/11/30/andrew-c...  \n",
       "3  [{'url': 'https://www.backpacker.com/stories/c...  \n",
       "4  [{'url': 'https://www.thefashionspot.com/forum...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_100.csv\")\n",
    "df[\"ranked_results\"] = df[\"ranked_results\"].apply(json.loads)\n",
    "\n",
    "print(f\"Loaded {len(df)} queries\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI client (shared by all models)\n",
    "client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_KEY\"],\n",
    "    api_version=\"2024-02-01\",\n",
    ")\n",
    "\n",
    "\n",
    "async def gpt_4_1(prompt: str, schema: dict) -> dict:\n",
    "    \"\"\"Call GPT-4.1 and return parsed JSON response.\"\"\"\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Respond with JSON matching: {json.dumps(schema)}\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        timeout=20,\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "async def phi_4(prompt: str, schema: dict) -> dict:\n",
    "    \"\"\"Call Phi-4 and return parsed JSON response.\"\"\"\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"Phi-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Respond with JSON matching: {json.dumps(schema)}\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        timeout=20,\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GPT-4.1 Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT-4.1] Processed 1/100\n",
      "[GPT-4.1] Processed 4/100\n",
      "[GPT-4.1] Processed 3/100\n",
      "[GPT-4.1] Processed 5/100\n",
      "[GPT-4.1] Processed 2/100\n",
      "[GPT-4.1] Processed 7/100\n",
      "[GPT-4.1] Processed 6/100\n",
      "[GPT-4.1] Processed 10/100\n",
      "[GPT-4.1] Processed 9/100\n",
      "[GPT-4.1] Processed 11/100\n",
      "[GPT-4.1] Processed 8/100\n",
      "[GPT-4.1] Processed 12/100\n",
      "[GPT-4.1] Processed 13/100\n",
      "[GPT-4.1] Processed 14/100\n",
      "[GPT-4.1] Processed 15/100\n",
      "[GPT-4.1] Processed 17/100\n",
      "[GPT-4.1] Processed 16/100\n",
      "[GPT-4.1] Processed 18/100\n",
      "[GPT-4.1] Processed 19/100\n",
      "[GPT-4.1] Processed 22/100\n",
      "[GPT-4.1] Processed 20/100\n",
      "[GPT-4.1] Processed 21/100\n",
      "[GPT-4.1] Processed 23/100\n",
      "[GPT-4.1] Processed 25/100\n",
      "[GPT-4.1] Processed 26/100\n",
      "[GPT-4.1] Processed 24/100\n",
      "[GPT-4.1] Processed 27/100\n",
      "[GPT-4.1] Processed 28/100\n",
      "[GPT-4.1] Processed 29/100\n",
      "[GPT-4.1] Processed 30/100\n",
      "[GPT-4.1] Processed 33/100\n",
      "[GPT-4.1] Processed 32/100\n",
      "[GPT-4.1] Processed 31/100\n",
      "[GPT-4.1] Processed 34/100\n",
      "[GPT-4.1] Processed 36/100\n",
      "[GPT-4.1] Processed 35/100\n",
      "[GPT-4.1] Processed 37/100\n",
      "[GPT-4.1] Processed 39/100\n",
      "[GPT-4.1] Processed 38/100\n",
      "[GPT-4.1] Processed 40/100\n",
      "[GPT-4.1] Processed 41/100\n",
      "[GPT-4.1] Processed 43/100\n",
      "[GPT-4.1] Processed 42/100\n",
      "[GPT-4.1] Processed 44/100\n",
      "[GPT-4.1] Processed 45/100\n",
      "[GPT-4.1] Processed 47/100\n",
      "[GPT-4.1] Processed 46/100\n",
      "[GPT-4.1] Processed 48/100\n",
      "[GPT-4.1] Processed 49/100\n",
      "[GPT-4.1] Processed 50/100\n",
      "[GPT-4.1] Processed 51/100\n",
      "[GPT-4.1] Processed 52/100\n",
      "[GPT-4.1] Processed 53/100\n",
      "[GPT-4.1] Processed 54/100\n",
      "[GPT-4.1] Processed 55/100\n",
      "[GPT-4.1] Processed 56/100\n",
      "[GPT-4.1] Processed 57/100\n",
      "[GPT-4.1] Processed 59/100\n",
      "[GPT-4.1] Processed 60/100\n",
      "[GPT-4.1] Processed 58/100\n",
      "[GPT-4.1] Processed 61/100\n",
      "[GPT-4.1] Processed 62/100\n",
      "[GPT-4.1] Processed 63/100\n",
      "[GPT-4.1] Processed 64/100\n",
      "[GPT-4.1] Processed 65/100\n",
      "[GPT-4.1] Processed 66/100\n",
      "[GPT-4.1] Processed 67/100\n",
      "[GPT-4.1] Processed 68/100\n",
      "[GPT-4.1] Processed 69/100\n",
      "[GPT-4.1] Processed 70/100\n",
      "[GPT-4.1] Processed 71/100\n",
      "[GPT-4.1] Processed 73/100\n",
      "[GPT-4.1] Processed 72/100\n",
      "[GPT-4.1] Processed 74/100\n",
      "[GPT-4.1] Processed 75/100\n",
      "[GPT-4.1] Processed 76/100\n",
      "[GPT-4.1] Processed 77/100\n",
      "[GPT-4.1] Processed 78/100\n",
      "[GPT-4.1] Processed 79/100\n",
      "[GPT-4.1] Processed 81/100\n",
      "[GPT-4.1] Processed 80/100\n",
      "[GPT-4.1] Processed 82/100\n",
      "[GPT-4.1] Processed 83/100\n",
      "[GPT-4.1] Processed 85/100\n",
      "[GPT-4.1] Processed 84/100\n",
      "[GPT-4.1] Processed 86/100\n",
      "[GPT-4.1] Processed 87/100\n",
      "[GPT-4.1] Processed 89/100\n",
      "[GPT-4.1] Processed 90/100\n",
      "[GPT-4.1] Processed 91/100\n",
      "[GPT-4.1] Processed 88/100\n",
      "[GPT-4.1] Processed 92/100\n",
      "[GPT-4.1] Processed 93/100\n",
      "[GPT-4.1] Processed 94/100\n",
      "[GPT-4.1] Processed 95/100\n",
      "[GPT-4.1] Processed 96/100\n",
      "[GPT-4.1] Processed 97/100\n",
      "[GPT-4.1] Processed 99/100\n",
      "[GPT-4.1] Processed 98/100\n",
      "[GPT-4.1] Processed 100/100\n"
     ]
    }
   ],
   "source": [
    "gpt_summaries = await run_summarization(df, gpt_4_1, \"GPT-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GPT-4.1 results to gpt_4_1_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Save GPT-4.1 results\n",
    "df_gpt = df.copy()\n",
    "df_gpt[\"summary\"] = gpt_summaries\n",
    "df_gpt.to_csv(\"gpt_4_1_summaries.csv\", index=False)\n",
    "print(\"Saved GPT-4.1 results to gpt_4_1_summaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Phi-4 Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phi-4] Processed 4/100\n",
      "[Phi-4] Processed 2/100\n",
      "[Phi-4] Processed 3/100\n",
      "[Phi-4] Processed 1/100\n",
      "[Phi-4] Processed 5/100\n",
      "[Phi-4] Processed 7/100\n",
      "[Phi-4] Processed 6/100\n",
      "[Phi-4] Processed 8/100\n",
      "[Phi-4] Processed 11/100\n",
      "[Phi-4] Processed 9/100\n",
      "[Phi-4] Processed 10/100\n",
      "[Phi-4] Processed 12/100\n",
      "[Phi-4] Processed 13/100\n",
      "[Phi-4] Processed 14/100\n",
      "[Phi-4] Processed 15/100\n",
      "[Phi-4] Processed 16/100\n",
      "[Phi-4] Processed 17/100\n",
      "[Phi-4] Processed 18/100\n",
      "[Phi-4] Processed 20/100\n",
      "[Phi-4] Processed 22/100\n",
      "[Phi-4] Processed 21/100\n",
      "[Phi-4] Processed 23/100\n",
      "[Phi-4] Processed 24/100\n",
      "[Phi-4] Processed 25/100\n",
      "[Phi-4] Processed 27/100\n",
      "[Phi-4] Processed 28/100\n",
      "[Phi-4] Processed 26/100\n",
      "[Phi-4] Processed 29/100\n",
      "[Phi-4] Processed 19/100\n",
      "[Phi-4] Processed 30/100\n",
      "[Phi-4] Processed 31/100\n",
      "[Phi-4] Processed 32/100\n",
      "[Phi-4] Processed 33/100\n",
      "[Phi-4] Processed 35/100\n",
      "[Phi-4] Processed 34/100\n",
      "[Phi-4] Processed 36/100\n",
      "[Phi-4] Processed 37/100\n",
      "[Phi-4] Processed 39/100\n",
      "[Phi-4] Processed 38/100\n",
      "[Phi-4] Processed 41/100\n",
      "[Phi-4] Processed 40/100\n",
      "[Phi-4] Processed 42/100\n",
      "[Phi-4] Processed 43/100\n",
      "[Phi-4] Processed 44/100\n",
      "[Phi-4] Processed 45/100\n",
      "[Phi-4] Processed 46/100\n",
      "[Phi-4] Processed 47/100\n",
      "[Phi-4] Processed 48/100\n",
      "[Phi-4] Processed 50/100\n",
      "[Phi-4] Processed 51/100\n",
      "[Phi-4] Processed 49/100\n",
      "[Phi-4] Processed 52/100\n",
      "[Phi-4] Processed 53/100\n",
      "[Phi-4] Processed 55/100\n",
      "[Phi-4] Processed 54/100\n",
      "[Phi-4] Processed 58/100\n",
      "[Phi-4] Processed 57/100\n",
      "[Phi-4] Processed 56/100\n",
      "[Phi-4] Processed 62/100\n",
      "[Phi-4] Processed 59/100\n",
      "[Phi-4] Processed 61/100\n",
      "[Phi-4] Processed 60/100\n",
      "[Phi-4] Processed 63/100\n",
      "[Phi-4] Processed 64/100\n",
      "[Phi-4] Processed 65/100\n",
      "[Phi-4] Processed 67/100\n",
      "[Phi-4] Processed 66/100\n",
      "[Phi-4] Processed 68/100\n",
      "[Phi-4] Processed 69/100\n",
      "[Phi-4] Processed 71/100\n",
      "[Phi-4] Processed 70/100\n",
      "[Phi-4] Processed 72/100\n",
      "[Phi-4] Processed 73/100\n",
      "[Phi-4] Processed 75/100\n",
      "[Phi-4] Processed 74/100\n",
      "[Phi-4] Processed 76/100\n",
      "[Phi-4] Processed 77/100\n",
      "[Phi-4] Processed 78/100\n",
      "[Phi-4] Processed 81/100\n",
      "[Phi-4] Processed 82/100\n",
      "[Phi-4] Processed 80/100\n",
      "[Phi-4] Processed 79/100\n",
      "[Phi-4] Processed 83/100\n",
      "[Phi-4] Processed 84/100\n",
      "[Phi-4] Processed 85/100\n",
      "[Phi-4] Processed 87/100\n",
      "[Phi-4] Processed 86/100\n",
      "[Phi-4] Processed 88/100\n",
      "[Phi-4] Processed 89/100\n",
      "[Phi-4] Processed 90/100\n",
      "[Phi-4] Processed 91/100\n",
      "[Phi-4] Processed 92/100\n",
      "[Phi-4] Processed 93/100\n",
      "[Phi-4] Processed 94/100\n",
      "[Phi-4] Processed 95/100\n",
      "[Phi-4] Processed 96/100\n",
      "[Phi-4] Processed 98/100\n",
      "[Phi-4] Processed 97/100\n",
      "[Phi-4] Processed 99/100\n",
      "[Phi-4] Processed 100/100\n"
     ]
    }
   ],
   "source": [
    "phi_summaries = await run_summarization(df, phi_4, \"Phi-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Phi-4 results to phi_4_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Phi-4 results\n",
    "df_phi = df.copy()\n",
    "df_phi[\"summary\"] = phi_summaries\n",
    "df_phi.to_csv(\"phi_4_summaries.csv\", index=False)\n",
    "print(\"Saved Phi-4 results to phi_4_summaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>gpt_4_1_summary</th>\n",
       "      <th>phi_4_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find reviews and recommendations f...</td>\n",
       "      <td>You can find reviews and recommendations for a...</td>\n",
       "      <td>To find reviews and recommendations for anti-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is big data really skillcrush</td>\n",
       "      <td>Big data refers to the large volumes of struct...</td>\n",
       "      <td>Big Data refers to extremely large datasets th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>growth secrets from tinder uber twitch andrew ...</td>\n",
       "      <td>On The Tim Ferriss Show, Andrew Chen shares in...</td>\n",
       "      <td>The search results focus on episodes of The Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stories about hiking in california trinity alp...</td>\n",
       "      <td>The search results highlight the Trinity Alps ...</td>\n",
       "      <td>The search results provide insights into hikin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who photographed Paulina Porizkova for the joy...</td>\n",
       "      <td>The search results indicate that Paulina Poriz...</td>\n",
       "      <td>Paulina Porizkova was photographed by Fabien B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tim ferriss rick rubin podcast transcript</td>\n",
       "      <td>In episode #649 of The Tim Ferriss Show, Tim F...</td>\n",
       "      <td>In the Tim Ferriss podcast episode #649, Rick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>once upon a chef green apple celery salad</td>\n",
       "      <td>The Once Upon a Chef green apple celery salad ...</td>\n",
       "      <td>The Green Apple and Celery Salad with Dill is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who is Niko Korner and what is their role at Y...</td>\n",
       "      <td>Niko Korner is a member of the Yoast team, as ...</td>\n",
       "      <td>Niko Korner is a member of the Yoast team, alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>litz rages in hueco climbing article by dougal...</td>\n",
       "      <td>The article 'Litz Rages in Hueco' highlights c...</td>\n",
       "      <td>In the article 'Litz Rages in Hueco' by Dougal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shanthi Rexaline entrepreneur author profile</td>\n",
       "      <td>Shanthi Rexaline is a contributor to Entrepren...</td>\n",
       "      <td>Shanthi Rexaline is recognized as an entrepren...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Where can I find reviews and recommendations f...   \n",
       "1                 what is big data really skillcrush   \n",
       "2  growth secrets from tinder uber twitch andrew ...   \n",
       "3  stories about hiking in california trinity alp...   \n",
       "4  Who photographed Paulina Porizkova for the joy...   \n",
       "5          tim ferriss rick rubin podcast transcript   \n",
       "6          once upon a chef green apple celery salad   \n",
       "7  Who is Niko Korner and what is their role at Y...   \n",
       "8  litz rages in hueco climbing article by dougal...   \n",
       "9       Shanthi Rexaline entrepreneur author profile   \n",
       "\n",
       "                                     gpt_4_1_summary  \\\n",
       "0  You can find reviews and recommendations for a...   \n",
       "1  Big data refers to the large volumes of struct...   \n",
       "2  On The Tim Ferriss Show, Andrew Chen shares in...   \n",
       "3  The search results highlight the Trinity Alps ...   \n",
       "4  The search results indicate that Paulina Poriz...   \n",
       "5  In episode #649 of The Tim Ferriss Show, Tim F...   \n",
       "6  The Once Upon a Chef green apple celery salad ...   \n",
       "7  Niko Korner is a member of the Yoast team, as ...   \n",
       "8  The article 'Litz Rages in Hueco' highlights c...   \n",
       "9  Shanthi Rexaline is a contributor to Entrepren...   \n",
       "\n",
       "                                       phi_4_summary  \n",
       "0  To find reviews and recommendations for anti-a...  \n",
       "1  Big Data refers to extremely large datasets th...  \n",
       "2  The search results focus on episodes of The Ti...  \n",
       "3  The search results provide insights into hikin...  \n",
       "4  Paulina Porizkova was photographed by Fabien B...  \n",
       "5  In the Tim Ferriss podcast episode #649, Rick ...  \n",
       "6  The Green Apple and Celery Salad with Dill is ...  \n",
       "7  Niko Korner is a member of the Yoast team, alt...  \n",
       "8  In the article 'Litz Rages in Hueco' by Dougal...  \n",
       "9  Shanthi Rexaline is recognized as an entrepren...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Side-by-side comparison\n",
    "comparison = pd.DataFrame({\n",
    "    \"query\": df[\"query_text\"],\n",
    "    \"gpt_4_1_summary\": gpt_summaries,\n",
    "    \"phi_4_summary\": phi_summaries,\n",
    "})\n",
    "comparison.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
