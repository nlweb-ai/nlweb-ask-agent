{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Specification Builder\n",
    "\n",
    "This notebook collects human preferences between GPT-4.1 and Phi-4 summaries,\n",
    "then generates a scoring specification via the `/scoring_system/generate` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 queries with summaries from both models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>gpt_summary</th>\n",
       "      <th>phi_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where can I find reviews and recommendations f...</td>\n",
       "      <td>You can find reviews and recommendations for a...</td>\n",
       "      <td>To find reviews and recommendations for anti-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is big data really skillcrush</td>\n",
       "      <td>Big data refers to the large volumes of struct...</td>\n",
       "      <td>Big Data refers to extremely large datasets th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>growth secrets from tinder uber twitch andrew ...</td>\n",
       "      <td>On The Tim Ferriss Show, Andrew Chen shares in...</td>\n",
       "      <td>The search results focus on episodes of The Ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0  Where can I find reviews and recommendations f...   \n",
       "1                 what is big data really skillcrush   \n",
       "2  growth secrets from tinder uber twitch andrew ...   \n",
       "\n",
       "                                         gpt_summary  \\\n",
       "0  You can find reviews and recommendations for a...   \n",
       "1  Big data refers to the large volumes of struct...   \n",
       "2  On The Tim Ferriss Show, Andrew Chen shares in...   \n",
       "\n",
       "                                         phi_summary  \n",
       "0  To find reviews and recommendations for anti-a...  \n",
       "1  Big Data refers to extremely large datasets th...  \n",
       "2  The search results focus on episodes of The Ti...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all three CSV files\n",
    "df_sample = pd.read_csv(\"sample_100.csv\")\n",
    "df_gpt = pd.read_csv(\"gpt_4_1_summaries.csv\")\n",
    "df_phi = pd.read_csv(\"phi_4_summaries.csv\")\n",
    "\n",
    "# Parse ranked_results JSON\n",
    "df_sample[\"ranked_results\"] = df_sample[\"ranked_results\"].apply(json.loads)\n",
    "\n",
    "# Merge summaries with original data\n",
    "df = df_sample.copy()\n",
    "df[\"gpt_summary\"] = df_gpt[\"summary\"]\n",
    "df[\"phi_summary\"] = df_phi[\"summary\"]\n",
    "\n",
    "print(f\"Loaded {len(df)} queries with summaries from both models\")\n",
    "df[[\"query_text\", \"gpt_summary\", \"phi_summary\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompt Reconstruction\n",
    "\n",
    "Reconstruct the exact prompt sent to the LLM models during summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example LLM input:\n",
      "------------------------------------------------------------\n",
      "Summarize the following search results in 2-3 sentences, highlighting the key information that answers the user's question: Where can I find reviews and recommendations for anti-aging skincare products from real users?\n",
      "\n",
      "Results:\n",
      "1. Beauty Favorites: skin care products I love + my anti-aging routine: Favorite Things, Lifestyle\n",
      "2. Beauty Favorites: skin care products I love + my anti-aging routine: \n",
      "3. https://centremarceau.com/medecine-esthetique/rajeunissement-de-la-peau/#primaryimage: \n"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"Summarize the following search results in 2-3 sentences, highlighting the key information that answers the user's question: {query}\n",
    "\n",
    "Results:\n",
    "{results}\"\"\"\n",
    "\n",
    "\n",
    "def extract_result_fields(result: dict) -> dict:\n",
    "    \"\"\"Extract name and description from schema.org result data.\"\"\"\n",
    "    content = result.get(\"content\", \"{}\")\n",
    "    if isinstance(content, str):\n",
    "        try:\n",
    "            content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            content = {}\n",
    "\n",
    "    # Try various schema.org fields for name\n",
    "    name = (\n",
    "        content.get(\"headline\")\n",
    "        or content.get(\"name\")\n",
    "        or content.get(\"caption\")\n",
    "        or result.get(\"url\", \"Unknown\")\n",
    "    )\n",
    "\n",
    "    # Try various fields for description\n",
    "    description = (\n",
    "        content.get(\"description\")\n",
    "        or content.get(\"articleSection\", \"\")\n",
    "        or \"\"\n",
    "    )\n",
    "    if isinstance(description, list):\n",
    "        description = \", \".join(description)\n",
    "\n",
    "    return {\"name\": name, \"description\": description}\n",
    "\n",
    "\n",
    "def build_llm_input(row) -> str:\n",
    "    \"\"\"Reconstruct the exact prompt sent to the LLM.\"\"\"\n",
    "    raw_results = row[\"ranked_results\"][:3]\n",
    "    results = [extract_result_fields(r) for r in raw_results]\n",
    "    results_text = \"\\n\".join(\n",
    "        f\"{i}. {r['name']}: {r['description']}\"\n",
    "        for i, r in enumerate(results, 1)\n",
    "    )\n",
    "    return PROMPT_TEMPLATE.format(query=row[\"query_text\"], results=results_text)\n",
    "\n",
    "\n",
    "# Test with first row\n",
    "print(\"Example LLM input:\")\n",
    "print(\"-\" * 60)\n",
    "print(build_llm_input(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 5 Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices: [76, 26, 52, 72, 60]\n",
      "\n",
      "1. [76] Is there a recipe for cakey baked donuts with apple cider reduction and cinnamon...\n",
      "\n",
      "2. [26] Is there a job guarantee with Skillcrush’s Break Into Tech Get Hired Track?...\n",
      "\n",
      "3. [52] valuewalk how to buy crypto UK article...\n",
      "\n",
      "4. [72] latest Harper's Bazaar Spain magazine covers April 2025...\n",
      "\n",
      "5. [60] Can you provide details about the website redesign project for the Trust Company...\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility (optional - remove for true randomness)\n",
    "# random.seed(42)\n",
    "\n",
    "# Sample 5 random indices\n",
    "sample_indices = random.sample(range(len(df)), 5)\n",
    "print(f\"Selected indices: {sample_indices}\")\n",
    "\n",
    "# Preview selected queries\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    print(f\"\\n{i}. [{idx}] {df.iloc[idx]['query_text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Preference Collection\n",
    "\n",
    "For each example, you'll see:\n",
    "- The query\n",
    "- Summary A (randomly assigned to GPT or Phi)\n",
    "- Summary B (the other model)\n",
    "\n",
    "Enter **A** or **B** to indicate your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================\n",
      "EXAMPLE 1/5 (Index: 76)\n",
      "=================================================================================\n",
      "\n",
      "QUERY: Is there a recipe for cakey baked donuts with apple cider reduction and cinnamon\n",
      "sugar coating?\n",
      "\n",
      "----------------------------------- SUMMARY A -----------------------------------\n",
      "There is a recipe for cakey baked donuts with apple cider reduction and cinnamon\n",
      "sugar coating. The baked apple cider donuts incorporate an apple cider reduction\n",
      "to enhance their flavor and are coated in cinnamon sugar, along with apple pie\n",
      "spices, making them a delightful fall treat. Another variation, Baked Cinnamon\n",
      "Crunch Apple Cider Doughnuts, offers a similar flavor profile to celebrate the\n",
      "autumn season.\n",
      "\n",
      "----------------------------------- SUMMARY B -----------------------------------\n",
      "Yes, there are recipes for cakey baked donuts that use an apple cider reduction\n",
      "to enhance flavor and are coated in a cinnamon sugar mixture. These donuts are\n",
      "described as soft, moist, and baked (not fried), making them easy to prepare and\n",
      "perfect for fall. The recipes highlight the combination of apple cider, warming\n",
      "spices, and a sweet cinnamon sugar coating.\n",
      "\n",
      "\n",
      ">> You chose: PHI\n",
      "\n",
      "=================================================================================\n",
      "EXAMPLE 2/5 (Index: 26)\n",
      "=================================================================================\n",
      "\n",
      "QUERY: Is there a job guarantee with Skillcrush’s Break Into Tech Get Hired Track?\n",
      "\n",
      "----------------------------------- SUMMARY A -----------------------------------\n",
      "Skillcrush's Break Into Tech Get Hired Track does not specifically offer a job\n",
      "guarantee, but it includes the Get Hired Track designed to enhance job placement\n",
      "chances. Additionally, Skillcrush provides career coaching to support students\n",
      "throughout their journey. The program aims to assist students in breaking into\n",
      "the tech industry but does not guarantee employment.\n",
      "\n",
      "----------------------------------- SUMMARY B -----------------------------------\n",
      "Skillcrush’s Break Into Tech Get Hired Track does not offer a formal job\n",
      "guarantee. Instead, Skillcrush provides career coaching and job search support to\n",
      "help students in their job hunt. While the program is designed to increase\n",
      "employment opportunities, securing a job is not guaranteed.\n",
      "\n",
      "\n",
      ">> You chose: GPT\n",
      "\n",
      "=================================================================================\n",
      "EXAMPLE 3/5 (Index: 52)\n",
      "=================================================================================\n",
      "\n",
      "QUERY: valuewalk how to buy crypto UK article\n",
      "\n",
      "----------------------------------- SUMMARY A -----------------------------------\n",
      "To buy cryptocurrency in the UK as of December 2025, it is essential to follow\n",
      "updated guides that detail steps for purchasing popular cryptocurrencies such as\n",
      "Bitcoin and Ethereum. Users can buy Bitcoin with a credit card using methods that\n",
      "might bypass traditional verification processes, simplifying the buying\n",
      "experience. These resources are particularly helpful for those new to\n",
      "cryptocurrency looking for straightforward acquisition methods.\n",
      "\n",
      "----------------------------------- SUMMARY B -----------------------------------\n",
      "The ValueWalk article on how to buy crypto in the UK outlines the steps for\n",
      "purchasing cryptocurrencies like Bitcoin and Ethereum, including choosing a\n",
      "reputable exchange, verifying your identity, and funding your account. It also\n",
      "mentions additional options such as buying with a credit card, sometimes with\n",
      "minimal or no verification, while highlighting the importance of considering fees\n",
      "and regulatory requirements. The guide provides updated information specific to\n",
      "UK residents for 2025.\n",
      "\n",
      "\n",
      ">> You chose: GPT\n",
      "\n",
      "=================================================================================\n",
      "EXAMPLE 4/5 (Index: 72)\n",
      "=================================================================================\n",
      "\n",
      "QUERY: latest Harper's Bazaar Spain magazine covers April 2025\n",
      "\n",
      "----------------------------------- SUMMARY A -----------------------------------\n",
      "The April 2025 covers of Harper's Bazaar Spain feature Carla Bruni, generating\n",
      "significant buzz and discussion online. Observers have noted that there is\n",
      "something unusual about her appearance on these covers. Visuals of the covers are\n",
      "available on the official Harper's Bazaar Spain website.\n",
      "\n",
      "----------------------------------- SUMMARY B -----------------------------------\n",
      "The April 2025 covers of Harper's Bazaar Spain feature Carla Bruni, drawing\n",
      "notable attention and discussion on forums due to something interesting about her\n",
      "portrayal. The magazine's website hosts the images, which are likely pivotal in\n",
      "generating buzz and commendation or critique about fashion trends and celebrity\n",
      "cover choices for that month.\n",
      "\n",
      "\n",
      ">> You chose: GPT\n",
      "\n",
      "=================================================================================\n",
      "EXAMPLE 5/5 (Index: 60)\n",
      "=================================================================================\n",
      "\n",
      "QUERY: Can you provide details about the website redesign project for the Trust Company\n",
      "of Vermont?\n",
      "\n",
      "----------------------------------- SUMMARY A -----------------------------------\n",
      "The Trust Company of Vermont initiated a website redesign project that culminated\n",
      "in a new homepage optimized for desktop viewing. The launch was reported by\n",
      "Bytes.co News and involved notable collaboration, with individuals like Jason\n",
      "DiVece leveraging his graphic design background and previous experiences in SEO\n",
      "to contribute to the project. Jason's career path, including time spent working\n",
      "with Peter Jewett, reflects the blending of technology and design expertise that\n",
      "shaped the redesign.\n",
      "\n",
      "----------------------------------- SUMMARY B -----------------------------------\n",
      "The Trust Company of Vermont recently launched a redesigned website, as announced\n",
      "in Bytes.co News. The new homepage features an updated design and improved user\n",
      "experience, aimed at better serving clients' needs online. The redesign project\n",
      "appears to be a collaborative effort involving professionals with backgrounds in\n",
      "graphic design and digital marketing.\n",
      "\n",
      "\n",
      ">> You chose: GPT\n",
      "\n",
      "\n",
      "=================================================================================\n",
      "PREFERENCE COLLECTION COMPLETE\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 81  # Matches header width: \"-\" * 35 + \" SUMMARY A \" + \"-\" * 35\n",
    "\n",
    "preferences = []\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    row = df.iloc[idx]\n",
    "    query = row[\"query_text\"]\n",
    "    gpt_summary = row[\"gpt_summary\"]\n",
    "    phi_summary = row[\"phi_summary\"]\n",
    "    \n",
    "    # Randomly assign A/B to prevent bias\n",
    "    if random.choice([True, False]):\n",
    "        summary_a, summary_b = gpt_summary, phi_summary\n",
    "        model_a, model_b = \"gpt\", \"phi\"\n",
    "    else:\n",
    "        summary_a, summary_b = phi_summary, gpt_summary\n",
    "        model_a, model_b = \"phi\", \"gpt\"\n",
    "    \n",
    "    # Display the comparison\n",
    "    print(\"=\" * WIDTH)\n",
    "    print(f\"EXAMPLE {i}/5 (Index: {idx})\")\n",
    "    print(\"=\" * WIDTH)\n",
    "    print(f\"\\nQUERY: {textwrap.fill(query, width=WIDTH)}\")\n",
    "    print(\"\\n\" + \"-\" * 35 + \" SUMMARY A \" + \"-\" * 35)\n",
    "    print(textwrap.fill(summary_a, width=WIDTH))\n",
    "    print(\"\\n\" + \"-\" * 35 + \" SUMMARY B \" + \"-\" * 35)\n",
    "    print(textwrap.fill(summary_b, width=WIDTH))\n",
    "    print()\n",
    "    \n",
    "    # Collect preference\n",
    "    while True:\n",
    "        choice = input(\"Which summary is better? Enter A or B: \").strip().upper()\n",
    "        if choice in [\"A\", \"B\"]:\n",
    "            break\n",
    "        print(\"Invalid input. Please enter A or B.\")\n",
    "    \n",
    "    # Record the preference\n",
    "    if choice == \"A\":\n",
    "        chosen_model = model_a\n",
    "        chosen_summary = summary_a\n",
    "        rejected_summary = summary_b\n",
    "    else:\n",
    "        chosen_model = model_b\n",
    "        chosen_summary = summary_b\n",
    "        rejected_summary = summary_a\n",
    "    \n",
    "    preferences.append({\n",
    "        \"index\": idx,\n",
    "        \"query\": query,\n",
    "        \"chosen_model\": chosen_model,\n",
    "        \"chosen_summary\": chosen_summary,\n",
    "        \"rejected_summary\": rejected_summary,\n",
    "        \"llm_input\": build_llm_input(row),\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n>> You chose: {chosen_model.upper()}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * WIDTH)\n",
    "print(\"PREFERENCE COLLECTION COMPLETE\")\n",
    "print(\"=\" * WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Collected Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferences collected: 5\n",
      "  GPT-4.1 chosen: 4\n",
      "  Phi-4 chosen: 1\n",
      "\n",
      "1. [76] PHI - Is there a recipe for cakey baked donuts with apple cider re...\n",
      "2. [26] GPT - Is there a job guarantee with Skillcrush’s Break Into Tech G...\n",
      "3. [52] GPT - valuewalk how to buy crypto UK article...\n",
      "4. [72] GPT - latest Harper's Bazaar Spain magazine covers April 2025...\n",
      "5. [60] GPT - Can you provide details about the website redesign project f...\n"
     ]
    }
   ],
   "source": [
    "# Summary of preferences\n",
    "gpt_wins = sum(1 for p in preferences if p[\"chosen_model\"] == \"gpt\")\n",
    "phi_wins = sum(1 for p in preferences if p[\"chosen_model\"] == \"phi\")\n",
    "\n",
    "print(f\"Preferences collected: {len(preferences)}\")\n",
    "print(f\"  GPT-4.1 chosen: {gpt_wins}\")\n",
    "print(f\"  Phi-4 chosen: {phi_wins}\")\n",
    "print()\n",
    "\n",
    "for i, p in enumerate(preferences, 1):\n",
    "    print(f\"{i}. [{p['index']}] {p['chosen_model'].upper()} - {p['query'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Preference Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 5 preference examples\n",
      "\n",
      "First example structure:\n",
      "{\n",
      "  \"llm_input\": \"Summarize the following search results in 2-3 sentences, highlighting the key information that answers the user's question: Is there a recipe for cakey baked donuts with apple cider reduction and cinn...\",\n",
      "  \"chosen\": \"There is a recipe for cakey baked donuts with apple cider reduction and cinnamon sugar coating. The ...\",\n",
      "  \"rejected\": \"Yes, there are recipes for cakey baked donuts that use an apple cider reduction to enhance flavor an...\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Build preference examples for the API\n",
    "preference_examples = [\n",
    "    {\n",
    "        \"llm_input\": p[\"llm_input\"],\n",
    "        \"chosen\": p[\"chosen_summary\"],\n",
    "        \"rejected\": p[\"rejected_summary\"],\n",
    "    }\n",
    "    for p in preferences\n",
    "]\n",
    "\n",
    "print(f\"Built {len(preference_examples)} preference examples\")\n",
    "print(\"\\nFirst example structure:\")\n",
    "print(json.dumps({\n",
    "    \"llm_input\": preference_examples[0][\"llm_input\"][:200] + \"...\",\n",
    "    \"chosen\": preference_examples[0][\"chosen\"][:100] + \"...\",\n",
    "    \"rejected\": preference_examples[0][\"rejected\"][:100] + \"...\",\n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Scoring Specification\n",
    "\n",
    "POST to the `/scoring_system/generate` endpoint to create a scoring spec based on preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request body preview:\n",
      "{\n",
      "  \"application_description\": \"Summarize search results in 2-3 sentences, highlighting the key information that answers the user's question.\",\n",
      "  \"examples\": [],\n",
      "  \"preference_examples\": \"[5 examples]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Build request body\n",
    "request_body = {\n",
    "    \"application_description\": \"Summarize search results in 2-3 sentences, highlighting the key information that answers the user's question.\",\n",
    "    \"examples\": [],\n",
    "    \"preference_examples\": preference_examples,\n",
    "}\n",
    "\n",
    "print(\"Request body preview:\")\n",
    "print(json.dumps({\n",
    "    \"application_description\": request_body[\"application_description\"],\n",
    "    \"examples\": request_body[\"examples\"],\n",
    "    \"preference_examples\": f\"[{len(preference_examples)} examples]\",\n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending POST request to http://localhost:8000/scoring_system/generate...\n",
      "\n",
      "SUCCESS! Scoring specification generated.\n",
      "\n",
      "======================================================================\n",
      "RESPONSE:\n",
      "======================================================================\n",
      "{\n",
      "  \"state\": \"QUEUED\",\n",
      "  \"detailed_status\": [\n",
      "    \"LAUNCHING\"\n",
      "  ],\n",
      "  \"job_id\": \"generate_spec_jobs:localuser:dcbe0c82-2d89-4038-ae7f-05fc34f054f0\",\n",
      "  \"scoring_spec\": null,\n",
      "  \"threshold\": null,\n",
      "  \"num_preference_examples_used\": null,\n",
      "  \"num_labeled_examples_used\": null,\n",
      "  \"balanced_accuracy\": null,\n",
      "  \"precision\": null,\n",
      "  \"recall\": null,\n",
      "  \"f1\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Send POST request to generate scoring specification\n",
    "API_URL = \"http://localhost:8000/scoring_system/generate\"\n",
    "\n",
    "print(f\"Sending POST request to {API_URL}...\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        API_URL,\n",
    "        json=request_body,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=120,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    print(\"SUCCESS! Scoring specification generated.\")\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESPONSE:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"ERROR: Could not connect to the API.\")\n",
    "    print(\"Make sure the server is running: cd ask_api && make dev\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"ERROR: Request timed out.\")\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"ERROR: HTTP {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to scoring_spec_output.json\n"
     ]
    }
   ],
   "source": [
    "# Optionally save the collected preferences and generated spec\n",
    "if 'result' in dir():\n",
    "    output = {\n",
    "        \"preferences\": preferences,\n",
    "        \"scoring_spec\": result,\n",
    "    }\n",
    "    \n",
    "    with open(\"scoring_spec_output.json\", \"w\") as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(\"Saved results to scoring_spec_output.json\")\n",
    "else:\n",
    "    print(\"No scoring spec to save (API call may have failed)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask-api (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
